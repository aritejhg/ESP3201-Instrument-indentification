{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPjvII6fbMZIc9BQkuPKHwd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aritejhg/ESP3201-Instrument-indentification/blob/main/VGGish_baseline_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This colab demonstrates how to extract the AudioSet embeddings, using a VGGish deep neural network (DNN).\n",
        "\n",
        "It's an updated version of malcolmslaney's original, modified to work with the updated tensorflow/models VGGish distribution, as well as TensorFlow 2."
      ],
      "metadata": {
        "id": "DgBODMCAnzuG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1Ds3Uuyrb4C"
      },
      "outputs": [],
      "source": [
        "# Upgrade pip first. Also make sure wheel is installed.\n",
        "!pip install --upgrade pip wheel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download original zip\n",
        "!wget https://zenodo.org/record/1432913/files/openmic-2018-v1.0.0.tgz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RN1ugAtKWG0u",
        "outputId": "a8d20400-d385-4b23-de35-6eac69d10d7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-03 03:08:48--  https://zenodo.org/record/1432913/files/openmic-2018-v1.0.0.tgz\n",
            "Resolving zenodo.org (zenodo.org)... 188.184.117.155\n",
            "Connecting to zenodo.org (zenodo.org)|188.184.117.155|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2623376754 (2.4G) [application/octet-stream]\n",
            "Saving to: ‘openmic-2018-v1.0.0.tgz’\n",
            "\n",
            "openmic-2018-v1.0.0 100%[===================>]   2.44G  22.7MB/s    in 2m 10s  \n",
            "\n",
            "2022-11-03 03:11:00 (19.2 MB/s) - ‘openmic-2018-v1.0.0.tgz’ saved [2623376754/2623376754]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# no need to copy zip to drive anymore since download is fast\n",
        "# %cp \"/content/openmic-2018-v1.0.0.tgz\" \"/content/drive/MyDrive/ESP3201/Datasets/openmic-2018-v1.0.0.tgz\""
      ],
      "metadata": {
        "id": "txycXlwmdvlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract and delete the zip\n",
        "!tar --extract --file /content/openmic-2018-v1.0.0.tgz\n",
        "!rm /content/openmic-2018-v1.0.0.tgz"
      ],
      "metadata": {
        "id": "Nyv1bcohe8tR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUrP9GpBIZp5",
        "outputId": "4302e5af-6ef5-4361-d100-8823fa42a86d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/openmic-2018"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yePIIieiGK_x",
        "outputId": "0f07c1fc-2cfe-42fb-da2a-5c5b2fb08604"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/openmic-2018\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "760fXB-BGU3M",
        "outputId": "e1105fd9-984e-4cd2-ec91-982f86f47ac0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/openmic-2018\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# These dependencies are necessary for loading the data\n",
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "#!pip install pandas\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "#import wandb\n",
        "#from wandb.keras import WandbCallback\n",
        "\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from sklearn.metrics import multilabel_confusion_matrix, classification_report"
      ],
      "metadata": {
        "id": "0Y9vcFuLESNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data using oepnmic-2018.npz"
      ],
      "metadata": {
        "id": "Y6UcLTQJGwc0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OPENMIC = np.load('openmic-2018.npz', allow_pickle=True)\n",
        "# rename columns to specific variables\n",
        "X, Y_true, Y_mask, sample_key = OPENMIC['X'], OPENMIC['Y_true'], OPENMIC['Y_mask'], OPENMIC['sample_key']\n",
        "\n",
        "# check data\n",
        "print(X.shape)\n",
        "print(Y_true.shape)\n",
        "print(Y_mask.shape)\n",
        "print(sample_key.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IPoXLKLEk5V",
        "outputId": "320ba4b1-6d6a-4409-a119-562bf104ae25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 10, 128)\n",
            "(20000, 20)\n",
            "(20000, 20)\n",
            "(20000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X[0])\n",
        "print(Y_true[0])\n",
        "print(Y_mask[0])\n",
        "print(sample_key[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIMPMG72G7zR",
        "outputId": "cd49222f-161d-46a9-f72b-f77e51445b94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[173  16 162 ...  42  37 255]\n",
            " [175  13 171 ...  55  82 255]\n",
            " [176  14 174 ... 153  59 255]\n",
            " ...\n",
            " [195  39 210 ...   0   0 255]\n",
            " [188  21 176 ...   0  96 255]\n",
            " [193  23 178 ...   0 200 255]]\n",
            "[0.5     0.5     0.5     0.5     0.17105 0.5     0.5     0.      0.5\n",
            " 0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.      0.5\n",
            " 0.5     0.5    ]\n",
            "[False False False False  True False False  True False False False False\n",
            " False False False False  True False False False]\n",
            "000046_3840\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the class map"
      ],
      "metadata": {
        "id": "BMdw0YdgG3oH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('class-map.json', 'r') as f:\n",
        "    class_map = json.load(f)\n",
        "print(class_map)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diNCmU0TFrBF",
        "outputId": "3d936f19-0014-4719-87c6-710bf48c10ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'accordion': 0, 'banjo': 1, 'bass': 2, 'cello': 3, 'clarinet': 4, 'cymbals': 5, 'drums': 6, 'flute': 7, 'guitar': 8, 'mallet_percussion': 9, 'mandolin': 10, 'organ': 11, 'piano': 12, 'saxophone': 13, 'synthesizer': 14, 'trombone': 15, 'trumpet': 16, 'ukulele': 17, 'violin': 18, 'voice': 19}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting data based on given train and test splits\n",
        "OpenMIC-2018 comes with a pre-defined train-test split. Great care was taken to ensure that this split is approximately balanced and artists are not represented in both sides of the split, so please use it!\n",
        "\n",
        "This is done by sample key, not row number, so you will need to go through the sample_key array to slice the data."
      ],
      "metadata": {
        "id": "OHeWq3XDHWcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's split the data into the training and test set\n",
        "# We use squeeze=True here to return a single array for each, rather than a full DataFrame\n",
        "\n",
        "split_train = pd.read_csv('partitions/split01_train.csv', \n",
        "                          header=None, squeeze=True)\n",
        "split_test = pd.read_csv('partitions/split01_test.csv', \n",
        "                         header=None, squeeze=True)"
      ],
      "metadata": {
        "id": "QYoRaTQiHOVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# These two tables contain the sample keys for training and testing examples\n",
        "# Let's see the keys for the first five training example\n",
        "split_train.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpI0kIlcHq2Q",
        "outputId": "c8f97156-4289-4126-dab0-167699ecb0ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      000046_3840\n",
              "1    000135_483840\n",
              "2    000139_119040\n",
              "3    000141_153600\n",
              "4     000144_30720\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many train and test examples do we have?  About 75%/25%\n",
        "print('# Train: {},  # Test: {}'.format(len(split_train), len(split_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cTzEeb2H8YE",
        "outputId": "e61c0fc9-8e19-4261-b001-169523e8bfa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Train: 14915,  # Test: 5085\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# easier to use as a set\n",
        "train_set = set(split_train)\n",
        "test_set = set(split_test)"
      ],
      "metadata": {
        "id": "EM5ZTkAwIAZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# These loops go through all sample keys, and save their row numbers\n",
        "# to either idx_train or idx_test\n",
        "#\n",
        "# This will be useful in the next step for slicing the array data\n",
        "idx_train, idx_test = [], []\n",
        "\n",
        "for idx, n in enumerate(sample_key):\n",
        "    if n in train_set:\n",
        "        idx_train.append(idx)\n",
        "    elif n in test_set:\n",
        "        idx_test.append(idx)\n",
        "    else:\n",
        "        # This should never happen, but better safe than sorry.\n",
        "        raise RuntimeError('Unknown sample key={}! Abort!'.format(sample_key[n]))\n",
        "        \n",
        "# Finally, cast the idx_* arrays to numpy structures\n",
        "idx_train = np.asarray(idx_train)\n",
        "idx_test = np.asarray(idx_test)"
      ],
      "metadata": {
        "id": "Uaq8qfFqIHFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(idx_train[20:30])\n",
        "print(idx_test[20:30])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0h9DB3hJAtM",
        "outputId": "fc80521f-b8ba-408a-82fd-e13198dbbfdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21 22 23 24 25 26 27 28 39 40]\n",
            "[ 60  73  74  98  99 100 109 110 117 118]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Finally, we use the split indices to partition the features, labels, and masks\n",
        "X_train = X[idx_train]\n",
        "X_test = X[idx_test]\n",
        "\n",
        "Y_true_train = Y_true[idx_train]\n",
        "Y_true_test = Y_true[idx_test]\n",
        "\n",
        "Y_mask_train = Y_mask[idx_train]\n",
        "Y_mask_test = Y_mask[idx_test]"
      ],
      "metadata": {
        "id": "qgkRA4_EJEWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out the sliced shapes as a sanity check\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwJfd3D0JPzD",
        "outputId": "6fc97ada-7d29-4f57-ca3a-f6ff614b864e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14915, 10, 128)\n",
            "(5085, 10, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the Y_true labels to binary\n",
        "print(Y_true_train[0])\n",
        "print(Y_true_test[0])\n",
        "print(Y_mask_train[0])\n",
        "\n",
        "Y_true_train[Y_mask_train==0] = 0\n",
        "Y_true_test[Y_mask_test==0] = 0\n",
        "\n",
        "print(Y_true_train[0])\n",
        "\n",
        "Y_train_labels = np.where(Y_true_train >= 0.5, 1, 0)\n",
        "Y_test_labels = np.where(Y_true_test >= 0.5, 1, 0)\n",
        "\n",
        "print(Y_train_labels[0])\n",
        "print(Y_test_labels[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJEQXj_oZ8fA",
        "outputId": "15e2413b-abc0-4b7c-e214-c42f85502fde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.5     0.5     0.5     0.5     0.17105 0.5     0.5     0.      0.5\n",
            " 0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.      0.5\n",
            " 0.5     0.5    ]\n",
            "[0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5\n",
            " 0.5 1. ]\n",
            "[False False False False  True False False  True False False False False\n",
            " False False False False  True False False False]\n",
            "[0.      0.      0.      0.      0.17105 0.      0.      0.      0.\n",
            " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
            " 0.      0.     ]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Tensorflow Dataset"
      ],
      "metadata": {
        "id": "J-FA5rrbL7-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_function(data, label):\n",
        "    \"\"\"Function that returns a tuple of normalized array and labels array.\n",
        "    Args:\n",
        "        data: array of the given data from X\n",
        "        label: 0/1 one-dimensional array of size N_LABELS\n",
        "    \"\"\"\n",
        "    # Normalize it from [0, 255] to [0.0, 1.0]\n",
        "    data_normalized = tf.cast(data, tf.float32) / 255.0\n",
        "    return data_normalized, label"
      ],
      "metadata": {
        "id": "_m2jsdP0L7nm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE # Adapt preprocessing and prefetching dynamically to reduce GPU and CPU idle time\n",
        "SHUFFLE_BUFFER_SIZE = 128 # Shuffle the training data by a chunck of 128 observations"
      ],
      "metadata": {
        "id": "97lQ8XM3MWn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(data, labels, is_training=True):\n",
        "    \"\"\"Load and parse dataset.\n",
        "    Args:\n",
        "        filenames: list of image paths\n",
        "        labels: numpy array of shape (BATCH_SIZE, N_LABELS)\n",
        "        is_training: boolean to indicate training mode\n",
        "    \"\"\"\n",
        "    \n",
        "    # Create a first dataset of file paths and labels\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
        "    # Parse and preprocess observations in parallel\n",
        "    dataset = dataset.map(normalize_function, num_parallel_calls=AUTOTUNE)\n",
        "    \n",
        "    # if is_training == True:\n",
        "    #     # This is a small dataset, only load it once, and keep it in memory.\n",
        "    #     dataset = dataset.cache()\n",
        "    # Shuffle the data each buffer size\n",
        "    dataset = dataset.shuffle(buffer_size=SHUFFLE_BUFFER_SIZE)\n",
        "        \n",
        "    # Batch the data for multiple steps\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    # Fetch batches in the background while the model is training.\n",
        "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "    \n",
        "    return dataset"
      ],
      "metadata": {
        "id": "YvJQlCyRLqzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = create_dataset(X_train, Y_train_labels)\n",
        "print(x_train)\n",
        "\n",
        "x_test = create_dataset(X_test, Y_test_labels)\n",
        "print(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJmvjKbXZxVi",
        "outputId": "493e8fe2-af79-432f-a817-17d4f2e50263"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 10, 128), dtype=tf.float32, name=None), TensorSpec(shape=(None, 20), dtype=tf.int64, name=None))>\n",
            "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 10, 128), dtype=tf.float32, name=None), TensorSpec(shape=(None, 20), dtype=tf.int64, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a classification layer"
      ],
      "metadata": {
        "id": "-9D99RjJJbyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "seeds = [1346, 76, 34, 46, 12]\n",
        "\n",
        "for seed in seeds:\n",
        "  tf.random.set_seed(seed)\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "\n",
        "  input = Input(shape =(10, 128))\n",
        "  # Fully connected layer classifier\n",
        "  x = Flatten()(input)\n",
        "  x = Dense(units = 4096, activation ='relu')(x)\n",
        "  x = Dropout(0.5)(x)\n",
        "  x = Dense(units = 4096, activation ='relu')(x)\n",
        "  # x = Dropout(0.5)(x)\n",
        "  output = Dense(units = 20, activation ='sigmoid')(x)\n",
        "  output = output[Y_mask]\n",
        "\n",
        "  # creating the model\n",
        "  model = Model (inputs=input, outputs = output)\n",
        "  model.summary()\n",
        "\n",
        "  LR = 1e-5 # Keep it small when transfer learning\n",
        "  EPOCHS = 30\n",
        "  loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
        "\n",
        "  model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=LR),\n",
        "    loss=loss_fn, metrics = ['Recall', 'Precision'])\n",
        "  \n",
        "  earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
        "  mcp_save = ModelCheckpoint(f'mdl_wts_{seed}.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
        "  reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=7, verbose=1, epsilon=1e-4, mode='min')\n",
        "\n",
        "  history = model.fit(x_train, epochs = EPOCHS, callbacks=[earlyStopping, mcp_save, reduce_lr_loss], validation_data = x_test)\n",
        "\n",
        "  # summarize history for loss\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title(f'model loss {seed}')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  plt.savefig(f'history_{seed}.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "it9OmcrBs3Us",
        "outputId": "0193eca2-7e9d-4492-987f-7ed92cf6e190"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_14 (InputLayer)       [(None, 10, 128)]         0         \n",
            "                                                                 \n",
            " flatten_13 (Flatten)        (None, 1280)              0         \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 4096)              5246976   \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 20)                81940     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 22,110,228\n",
            "Trainable params: 22,110,228\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "117/117 [==============================] - 3s 22ms/step - loss: 0.2208 - recall: 0.0172 - precision: 0.0512 - val_loss: 0.1666 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-05\n",
            "Epoch 2/30\n",
            "117/117 [==============================] - 2s 19ms/step - loss: 0.1558 - recall: 0.0082 - precision: 1.0000 - val_loss: 0.1386 - val_recall: 0.0252 - val_precision: 0.9828 - lr: 1.0000e-05\n",
            "Epoch 3/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.1286 - recall: 0.0632 - precision: 0.9528 - val_loss: 0.1122 - val_recall: 0.1260 - val_precision: 0.9237 - lr: 1.0000e-05\n",
            "Epoch 4/30\n",
            "117/117 [==============================] - 3s 22ms/step - loss: 0.1080 - recall: 0.1956 - precision: 0.8893 - val_loss: 0.0978 - val_recall: 0.2497 - val_precision: 0.8637 - lr: 1.0000e-05\n",
            "Epoch 5/30\n",
            "117/117 [==============================] - 2s 19ms/step - loss: 0.0966 - recall: 0.2981 - precision: 0.8313 - val_loss: 0.0908 - val_recall: 0.3334 - val_precision: 0.8325 - lr: 1.0000e-05\n",
            "Epoch 6/30\n",
            "117/117 [==============================] - 2s 19ms/step - loss: 0.0901 - recall: 0.3637 - precision: 0.8065 - val_loss: 0.0868 - val_recall: 0.3783 - val_precision: 0.8058 - lr: 1.0000e-05\n",
            "Epoch 7/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0859 - recall: 0.4046 - precision: 0.8012 - val_loss: 0.0845 - val_recall: 0.4098 - val_precision: 0.7968 - lr: 1.0000e-05\n",
            "Epoch 8/30\n",
            "117/117 [==============================] - 2s 21ms/step - loss: 0.0834 - recall: 0.4309 - precision: 0.7975 - val_loss: 0.0824 - val_recall: 0.4408 - val_precision: 0.7926 - lr: 1.0000e-05\n",
            "Epoch 9/30\n",
            "117/117 [==============================] - 2s 18ms/step - loss: 0.0809 - recall: 0.4532 - precision: 0.7949 - val_loss: 0.0812 - val_recall: 0.4523 - val_precision: 0.7879 - lr: 1.0000e-05\n",
            "Epoch 10/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0791 - recall: 0.4665 - precision: 0.7912 - val_loss: 0.0802 - val_recall: 0.4651 - val_precision: 0.7825 - lr: 1.0000e-05\n",
            "Epoch 11/30\n",
            "117/117 [==============================] - 2s 19ms/step - loss: 0.0777 - recall: 0.4788 - precision: 0.7898 - val_loss: 0.0793 - val_recall: 0.4731 - val_precision: 0.7805 - lr: 1.0000e-05\n",
            "Epoch 12/30\n",
            "117/117 [==============================] - 2s 21ms/step - loss: 0.0764 - recall: 0.4935 - precision: 0.7906 - val_loss: 0.0786 - val_recall: 0.4835 - val_precision: 0.7789 - lr: 1.0000e-05\n",
            "Epoch 13/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0752 - recall: 0.5029 - precision: 0.7937 - val_loss: 0.0778 - val_recall: 0.4981 - val_precision: 0.7753 - lr: 1.0000e-05\n",
            "Epoch 14/30\n",
            "117/117 [==============================] - 2s 21ms/step - loss: 0.0743 - recall: 0.5123 - precision: 0.7979 - val_loss: 0.0772 - val_recall: 0.5028 - val_precision: 0.7772 - lr: 1.0000e-05\n",
            "Epoch 15/30\n",
            "117/117 [==============================] - 3s 26ms/step - loss: 0.0735 - recall: 0.5158 - precision: 0.7938 - val_loss: 0.0767 - val_recall: 0.5061 - val_precision: 0.7731 - lr: 1.0000e-05\n",
            "Epoch 16/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0724 - recall: 0.5231 - precision: 0.7955 - val_loss: 0.0763 - val_recall: 0.5149 - val_precision: 0.7746 - lr: 1.0000e-05\n",
            "Epoch 17/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0717 - recall: 0.5331 - precision: 0.7979 - val_loss: 0.0758 - val_recall: 0.5149 - val_precision: 0.7740 - lr: 1.0000e-05\n",
            "Epoch 18/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0707 - recall: 0.5343 - precision: 0.7984 - val_loss: 0.0757 - val_recall: 0.5187 - val_precision: 0.7720 - lr: 1.0000e-05\n",
            "Epoch 19/30\n",
            "117/117 [==============================] - 2s 18ms/step - loss: 0.0704 - recall: 0.5355 - precision: 0.7979 - val_loss: 0.0752 - val_recall: 0.5225 - val_precision: 0.7733 - lr: 1.0000e-05\n",
            "Epoch 20/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0695 - recall: 0.5454 - precision: 0.7989 - val_loss: 0.0752 - val_recall: 0.5280 - val_precision: 0.7723 - lr: 1.0000e-05\n",
            "Epoch 21/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0691 - recall: 0.5466 - precision: 0.7995 - val_loss: 0.0748 - val_recall: 0.5284 - val_precision: 0.7725 - lr: 1.0000e-05\n",
            "Epoch 22/30\n",
            "117/117 [==============================] - 2s 19ms/step - loss: 0.0686 - recall: 0.5494 - precision: 0.7974 - val_loss: 0.0744 - val_recall: 0.5366 - val_precision: 0.7700 - lr: 1.0000e-05\n",
            "Epoch 23/30\n",
            "117/117 [==============================] - 2s 13ms/step - loss: 0.0679 - recall: 0.5555 - precision: 0.8020 - val_loss: 0.0744 - val_recall: 0.5439 - val_precision: 0.7659 - lr: 1.0000e-05\n",
            "Epoch 24/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0673 - recall: 0.5599 - precision: 0.8041 - val_loss: 0.0740 - val_recall: 0.5462 - val_precision: 0.7702 - lr: 1.0000e-05\n",
            "Epoch 25/30\n",
            "117/117 [==============================] - 2s 13ms/step - loss: 0.0670 - recall: 0.5647 - precision: 0.8083 - val_loss: 0.0741 - val_recall: 0.5495 - val_precision: 0.7639 - lr: 1.0000e-05\n",
            "Epoch 26/30\n",
            "117/117 [==============================] - 2s 19ms/step - loss: 0.0662 - recall: 0.5697 - precision: 0.8044 - val_loss: 0.0737 - val_recall: 0.5493 - val_precision: 0.7691 - lr: 1.0000e-05\n",
            "Epoch 27/30\n",
            "117/117 [==============================] - 2s 19ms/step - loss: 0.0657 - recall: 0.5730 - precision: 0.8077 - val_loss: 0.0735 - val_recall: 0.5532 - val_precision: 0.7682 - lr: 1.0000e-05\n",
            "Epoch 28/30\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.0655 - recall: 0.5748 - precision: 0.8088 - val_loss: 0.0736 - val_recall: 0.5524 - val_precision: 0.7635 - lr: 1.0000e-05\n",
            "Epoch 29/30\n",
            "117/117 [==============================] - 2s 18ms/step - loss: 0.0650 - recall: 0.5771 - precision: 0.8074 - val_loss: 0.0733 - val_recall: 0.5568 - val_precision: 0.7677 - lr: 1.0000e-05\n",
            "Epoch 30/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0647 - recall: 0.5760 - precision: 0.8058 - val_loss: 0.0732 - val_recall: 0.5517 - val_precision: 0.7682 - lr: 1.0000e-05\n",
            "Model: \"model_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_15 (InputLayer)       [(None, 10, 128)]         0         \n",
            "                                                                 \n",
            " flatten_14 (Flatten)        (None, 1280)              0         \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 4096)              5246976   \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dense_44 (Dense)            (None, 20)                81940     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 22,110,228\n",
            "Trainable params: 22,110,228\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "117/117 [==============================] - 3s 21ms/step - loss: 0.2288 - recall: 0.0164 - precision: 0.0377 - val_loss: 0.1674 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-05\n",
            "Epoch 2/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.1569 - recall: 0.0033 - precision: 1.0000 - val_loss: 0.1393 - val_recall: 0.0204 - val_precision: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 3/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.1299 - recall: 0.0570 - precision: 0.9455 - val_loss: 0.1134 - val_recall: 0.1158 - val_precision: 0.9423 - lr: 1.0000e-05\n",
            "Epoch 4/30\n",
            "117/117 [==============================] - 2s 18ms/step - loss: 0.1092 - recall: 0.1835 - precision: 0.8870 - val_loss: 0.0986 - val_recall: 0.2395 - val_precision: 0.8740 - lr: 1.0000e-05\n",
            "Epoch 5/30\n",
            "117/117 [==============================] - 3s 23ms/step - loss: 0.0973 - recall: 0.2882 - precision: 0.8359 - val_loss: 0.0912 - val_recall: 0.3192 - val_precision: 0.8393 - lr: 1.0000e-05\n",
            "Epoch 6/30\n",
            "117/117 [==============================] - 2s 18ms/step - loss: 0.0906 - recall: 0.3589 - precision: 0.8165 - val_loss: 0.0869 - val_recall: 0.3764 - val_precision: 0.8146 - lr: 1.0000e-05\n",
            "Epoch 7/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0863 - recall: 0.4009 - precision: 0.8039 - val_loss: 0.0842 - val_recall: 0.4069 - val_precision: 0.8051 - lr: 1.0000e-05\n",
            "Epoch 8/30\n",
            "117/117 [==============================] - 2s 19ms/step - loss: 0.0834 - recall: 0.4293 - precision: 0.7971 - val_loss: 0.0825 - val_recall: 0.4383 - val_precision: 0.7949 - lr: 1.0000e-05\n",
            "Epoch 9/30\n",
            "117/117 [==============================] - 2s 18ms/step - loss: 0.0813 - recall: 0.4507 - precision: 0.7915 - val_loss: 0.0811 - val_recall: 0.4510 - val_precision: 0.7895 - lr: 1.0000e-05\n",
            "Epoch 10/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0795 - recall: 0.4657 - precision: 0.7898 - val_loss: 0.0803 - val_recall: 0.4689 - val_precision: 0.7804 - lr: 1.0000e-05\n",
            "Epoch 11/30\n",
            "117/117 [==============================] - 2s 18ms/step - loss: 0.0783 - recall: 0.4778 - precision: 0.7916 - val_loss: 0.0792 - val_recall: 0.4758 - val_precision: 0.7789 - lr: 1.0000e-05\n",
            "Epoch 12/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0766 - recall: 0.4913 - precision: 0.7898 - val_loss: 0.0786 - val_recall: 0.4848 - val_precision: 0.7752 - lr: 1.0000e-05\n",
            "Epoch 13/30\n",
            "117/117 [==============================] - 2s 19ms/step - loss: 0.0755 - recall: 0.4991 - precision: 0.7887 - val_loss: 0.0777 - val_recall: 0.4913 - val_precision: 0.7778 - lr: 1.0000e-05\n",
            "Epoch 14/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0743 - recall: 0.5083 - precision: 0.7895 - val_loss: 0.0772 - val_recall: 0.5014 - val_precision: 0.7757 - lr: 1.0000e-05\n",
            "Epoch 15/30\n",
            "117/117 [==============================] - 2s 19ms/step - loss: 0.0736 - recall: 0.5151 - precision: 0.7924 - val_loss: 0.0769 - val_recall: 0.5096 - val_precision: 0.7730 - lr: 1.0000e-05\n",
            "Epoch 16/30\n",
            "117/117 [==============================] - 3s 26ms/step - loss: 0.0728 - recall: 0.5199 - precision: 0.7944 - val_loss: 0.0763 - val_recall: 0.5134 - val_precision: 0.7753 - lr: 1.0000e-05\n",
            "Epoch 17/30\n",
            "117/117 [==============================] - 3s 26ms/step - loss: 0.0721 - recall: 0.5245 - precision: 0.7921 - val_loss: 0.0759 - val_recall: 0.5191 - val_precision: 0.7755 - lr: 1.0000e-05\n",
            "Epoch 18/30\n",
            "117/117 [==============================] - 2s 19ms/step - loss: 0.0711 - recall: 0.5313 - precision: 0.7981 - val_loss: 0.0755 - val_recall: 0.5222 - val_precision: 0.7780 - lr: 1.0000e-05\n",
            "Epoch 19/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0703 - recall: 0.5391 - precision: 0.8000 - val_loss: 0.0753 - val_recall: 0.5249 - val_precision: 0.7774 - lr: 1.0000e-05\n",
            "Epoch 20/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0699 - recall: 0.5414 - precision: 0.7974 - val_loss: 0.0750 - val_recall: 0.5293 - val_precision: 0.7755 - lr: 1.0000e-05\n",
            "Epoch 21/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0694 - recall: 0.5456 - precision: 0.8007 - val_loss: 0.0746 - val_recall: 0.5338 - val_precision: 0.7723 - lr: 1.0000e-05\n",
            "Epoch 22/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0685 - recall: 0.5549 - precision: 0.8013 - val_loss: 0.0746 - val_recall: 0.5384 - val_precision: 0.7721 - lr: 1.0000e-05\n",
            "Epoch 23/30\n",
            "117/117 [==============================] - 3s 26ms/step - loss: 0.0680 - recall: 0.5571 - precision: 0.8032 - val_loss: 0.0743 - val_recall: 0.5384 - val_precision: 0.7758 - lr: 1.0000e-05\n",
            "Epoch 24/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0675 - recall: 0.5623 - precision: 0.8045 - val_loss: 0.0740 - val_recall: 0.5402 - val_precision: 0.7748 - lr: 1.0000e-05\n",
            "Epoch 25/30\n",
            "117/117 [==============================] - 2s 21ms/step - loss: 0.0669 - recall: 0.5665 - precision: 0.8012 - val_loss: 0.0738 - val_recall: 0.5433 - val_precision: 0.7732 - lr: 1.0000e-05\n",
            "Epoch 26/30\n",
            "117/117 [==============================] - 2s 13ms/step - loss: 0.0665 - recall: 0.5662 - precision: 0.8045 - val_loss: 0.0740 - val_recall: 0.5486 - val_precision: 0.7717 - lr: 1.0000e-05\n",
            "Epoch 27/30\n",
            "117/117 [==============================] - 2s 18ms/step - loss: 0.0660 - recall: 0.5717 - precision: 0.8086 - val_loss: 0.0735 - val_recall: 0.5495 - val_precision: 0.7706 - lr: 1.0000e-05\n",
            "Epoch 28/30\n",
            "117/117 [==============================] - 2s 19ms/step - loss: 0.0656 - recall: 0.5728 - precision: 0.8103 - val_loss: 0.0735 - val_recall: 0.5513 - val_precision: 0.7699 - lr: 1.0000e-05\n",
            "Epoch 29/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0651 - recall: 0.5756 - precision: 0.8079 - val_loss: 0.0734 - val_recall: 0.5535 - val_precision: 0.7690 - lr: 1.0000e-05\n",
            "Epoch 30/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0647 - recall: 0.5804 - precision: 0.8092 - val_loss: 0.0731 - val_recall: 0.5539 - val_precision: 0.7708 - lr: 1.0000e-05\n",
            "Model: \"model_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_16 (InputLayer)       [(None, 10, 128)]         0         \n",
            "                                                                 \n",
            " flatten_15 (Flatten)        (None, 1280)              0         \n",
            "                                                                 \n",
            " dense_45 (Dense)            (None, 4096)              5246976   \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_46 (Dense)            (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 20)                81940     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 22,110,228\n",
            "Trainable params: 22,110,228\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "117/117 [==============================] - 3s 21ms/step - loss: 0.2263 - recall: 0.0241 - precision: 0.0548 - val_loss: 0.1670 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-05\n",
            "Epoch 2/30\n",
            "117/117 [==============================] - 2s 19ms/step - loss: 0.1563 - recall: 0.0056 - precision: 1.0000 - val_loss: 0.1390 - val_recall: 0.0221 - val_precision: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 3/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.1288 - recall: 0.0632 - precision: 0.9420 - val_loss: 0.1131 - val_recall: 0.1233 - val_precision: 0.9283 - lr: 1.0000e-05\n",
            "Epoch 4/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.1084 - recall: 0.1942 - precision: 0.8827 - val_loss: 0.0983 - val_recall: 0.2477 - val_precision: 0.8688 - lr: 1.0000e-05\n",
            "Epoch 5/30\n",
            "117/117 [==============================] - 2s 19ms/step - loss: 0.0969 - recall: 0.2979 - precision: 0.8335 - val_loss: 0.0910 - val_recall: 0.3294 - val_precision: 0.8317 - lr: 1.0000e-05\n",
            "Epoch 6/30\n",
            "117/117 [==============================] - 2s 19ms/step - loss: 0.0904 - recall: 0.3608 - precision: 0.8097 - val_loss: 0.0868 - val_recall: 0.3746 - val_precision: 0.8096 - lr: 1.0000e-05\n",
            "Epoch 7/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0868 - recall: 0.3992 - precision: 0.7957 - val_loss: 0.0842 - val_recall: 0.4098 - val_precision: 0.8037 - lr: 1.0000e-05\n",
            "Epoch 8/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0835 - recall: 0.4290 - precision: 0.7902 - val_loss: 0.0826 - val_recall: 0.4304 - val_precision: 0.7980 - lr: 1.0000e-05\n",
            "Epoch 9/30\n",
            "117/117 [==============================] - 2s 18ms/step - loss: 0.0813 - recall: 0.4519 - precision: 0.7965 - val_loss: 0.0811 - val_recall: 0.4552 - val_precision: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 10/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0795 - recall: 0.4690 - precision: 0.7902 - val_loss: 0.0802 - val_recall: 0.4634 - val_precision: 0.7851 - lr: 1.0000e-05\n",
            "Epoch 11/30\n",
            "117/117 [==============================] - 3s 22ms/step - loss: 0.0780 - recall: 0.4809 - precision: 0.7883 - val_loss: 0.0792 - val_recall: 0.4716 - val_precision: 0.7851 - lr: 1.0000e-05\n",
            "Epoch 12/30\n",
            "117/117 [==============================] - 2s 21ms/step - loss: 0.0766 - recall: 0.4890 - precision: 0.7870 - val_loss: 0.0783 - val_recall: 0.4888 - val_precision: 0.7813 - lr: 1.0000e-05\n",
            "Epoch 13/30\n",
            "117/117 [==============================] - 2s 19ms/step - loss: 0.0752 - recall: 0.4981 - precision: 0.7934 - val_loss: 0.0777 - val_recall: 0.4986 - val_precision: 0.7787 - lr: 1.0000e-05\n",
            "Epoch 14/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0747 - recall: 0.5068 - precision: 0.7896 - val_loss: 0.0771 - val_recall: 0.5028 - val_precision: 0.7807 - lr: 1.0000e-05\n",
            "Epoch 15/30\n",
            "117/117 [==============================] - 2s 19ms/step - loss: 0.0734 - recall: 0.5157 - precision: 0.7946 - val_loss: 0.0766 - val_recall: 0.5072 - val_precision: 0.7819 - lr: 1.0000e-05\n",
            "Epoch 16/30\n",
            "117/117 [==============================] - 2s 21ms/step - loss: 0.0723 - recall: 0.5216 - precision: 0.7976 - val_loss: 0.0762 - val_recall: 0.5141 - val_precision: 0.7779 - lr: 1.0000e-05\n",
            "Epoch 17/30\n",
            "117/117 [==============================] - 2s 18ms/step - loss: 0.0721 - recall: 0.5260 - precision: 0.7915 - val_loss: 0.0757 - val_recall: 0.5172 - val_precision: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 18/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0713 - recall: 0.5332 - precision: 0.7949 - val_loss: 0.0753 - val_recall: 0.5209 - val_precision: 0.7815 - lr: 1.0000e-05\n",
            "Epoch 19/30\n",
            "117/117 [==============================] - 3s 22ms/step - loss: 0.0705 - recall: 0.5378 - precision: 0.7973 - val_loss: 0.0749 - val_recall: 0.5284 - val_precision: 0.7785 - lr: 1.0000e-05\n",
            "Epoch 20/30\n",
            "117/117 [==============================] - 2s 21ms/step - loss: 0.0700 - recall: 0.5394 - precision: 0.7987 - val_loss: 0.0747 - val_recall: 0.5298 - val_precision: 0.7797 - lr: 1.0000e-05\n",
            "Epoch 21/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0692 - recall: 0.5477 - precision: 0.8024 - val_loss: 0.0745 - val_recall: 0.5344 - val_precision: 0.7772 - lr: 1.0000e-05\n",
            "Epoch 22/30\n",
            "117/117 [==============================] - 2s 19ms/step - loss: 0.0686 - recall: 0.5532 - precision: 0.8001 - val_loss: 0.0742 - val_recall: 0.5369 - val_precision: 0.7755 - lr: 1.0000e-05\n",
            "Epoch 23/30\n",
            "117/117 [==============================] - 2s 21ms/step - loss: 0.0680 - recall: 0.5572 - precision: 0.8022 - val_loss: 0.0740 - val_recall: 0.5366 - val_precision: 0.7814 - lr: 1.0000e-05\n",
            "Epoch 24/30\n",
            "117/117 [==============================] - 2s 18ms/step - loss: 0.0676 - recall: 0.5578 - precision: 0.8056 - val_loss: 0.0738 - val_recall: 0.5400 - val_precision: 0.7777 - lr: 1.0000e-05\n",
            "Epoch 25/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0670 - recall: 0.5621 - precision: 0.8041 - val_loss: 0.0738 - val_recall: 0.5435 - val_precision: 0.7744 - lr: 1.0000e-05\n",
            "Epoch 26/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0667 - recall: 0.5661 - precision: 0.8034 - val_loss: 0.0735 - val_recall: 0.5521 - val_precision: 0.7717 - lr: 1.0000e-05\n",
            "Epoch 27/30\n",
            "117/117 [==============================] - 2s 18ms/step - loss: 0.0659 - recall: 0.5704 - precision: 0.8066 - val_loss: 0.0733 - val_recall: 0.5457 - val_precision: 0.7769 - lr: 1.0000e-05\n",
            "Epoch 28/30\n",
            "117/117 [==============================] - 1s 13ms/step - loss: 0.0655 - recall: 0.5701 - precision: 0.8059 - val_loss: 0.0733 - val_recall: 0.5544 - val_precision: 0.7724 - lr: 1.0000e-05\n",
            "Epoch 29/30\n",
            "117/117 [==============================] - 2s 13ms/step - loss: 0.0653 - recall: 0.5763 - precision: 0.8059 - val_loss: 0.0733 - val_recall: 0.5544 - val_precision: 0.7740 - lr: 1.0000e-05\n",
            "Epoch 30/30\n",
            "117/117 [==============================] - 2s 19ms/step - loss: 0.0645 - recall: 0.5810 - precision: 0.8095 - val_loss: 0.0730 - val_recall: 0.5555 - val_precision: 0.7732 - lr: 1.0000e-05\n",
            "Model: \"model_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_17 (InputLayer)       [(None, 10, 128)]         0         \n",
            "                                                                 \n",
            " flatten_16 (Flatten)        (None, 1280)              0         \n",
            "                                                                 \n",
            " dense_48 (Dense)            (None, 4096)              5246976   \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dense_50 (Dense)            (None, 20)                81940     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 22,110,228\n",
            "Trainable params: 22,110,228\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "117/117 [==============================] - 4s 30ms/step - loss: 0.2178 - recall: 0.0142 - precision: 0.0544 - val_loss: 0.1663 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-05\n",
            "Epoch 2/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.1553 - recall: 0.0075 - precision: 0.9899 - val_loss: 0.1379 - val_recall: 0.0310 - val_precision: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 3/30\n",
            "117/117 [==============================] - 2s 18ms/step - loss: 0.1276 - recall: 0.0690 - precision: 0.9506 - val_loss: 0.1116 - val_recall: 0.1337 - val_precision: 0.9364 - lr: 1.0000e-05\n",
            "Epoch 4/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.1073 - recall: 0.2021 - precision: 0.8865 - val_loss: 0.0975 - val_recall: 0.2621 - val_precision: 0.8674 - lr: 1.0000e-05\n",
            "Epoch 5/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0964 - recall: 0.3040 - precision: 0.8379 - val_loss: 0.0907 - val_recall: 0.3314 - val_precision: 0.8303 - lr: 1.0000e-05\n",
            "Epoch 6/30\n",
            "117/117 [==============================] - 2s 19ms/step - loss: 0.0906 - recall: 0.3634 - precision: 0.8061 - val_loss: 0.0869 - val_recall: 0.3719 - val_precision: 0.8167 - lr: 1.0000e-05\n",
            "Epoch 7/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0863 - recall: 0.4051 - precision: 0.8015 - val_loss: 0.0843 - val_recall: 0.4054 - val_precision: 0.8063 - lr: 1.0000e-05\n",
            "Epoch 8/30\n",
            "117/117 [==============================] - 2s 18ms/step - loss: 0.0833 - recall: 0.4354 - precision: 0.7954 - val_loss: 0.0825 - val_recall: 0.4346 - val_precision: 0.7993 - lr: 1.0000e-05\n",
            "Epoch 9/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0812 - recall: 0.4557 - precision: 0.7981 - val_loss: 0.0810 - val_recall: 0.4518 - val_precision: 0.7929 - lr: 1.0000e-05\n",
            "Epoch 10/30\n",
            "117/117 [==============================] - 2s 19ms/step - loss: 0.0791 - recall: 0.4709 - precision: 0.7938 - val_loss: 0.0801 - val_recall: 0.4598 - val_precision: 0.7909 - lr: 1.0000e-05\n",
            "Epoch 11/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0777 - recall: 0.4799 - precision: 0.7901 - val_loss: 0.0792 - val_recall: 0.4704 - val_precision: 0.7847 - lr: 1.0000e-05\n",
            "Epoch 12/30\n",
            "117/117 [==============================] - 2s 18ms/step - loss: 0.0763 - recall: 0.4950 - precision: 0.7919 - val_loss: 0.0784 - val_recall: 0.4831 - val_precision: 0.7849 - lr: 1.0000e-05\n",
            "Epoch 13/30\n",
            "117/117 [==============================] - 2s 19ms/step - loss: 0.0754 - recall: 0.4985 - precision: 0.7889 - val_loss: 0.0777 - val_recall: 0.4897 - val_precision: 0.7822 - lr: 1.0000e-05\n",
            "Epoch 14/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0743 - recall: 0.5069 - precision: 0.7939 - val_loss: 0.0770 - val_recall: 0.5003 - val_precision: 0.7807 - lr: 1.0000e-05\n",
            "Epoch 15/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0735 - recall: 0.5166 - precision: 0.7963 - val_loss: 0.0765 - val_recall: 0.5054 - val_precision: 0.7789 - lr: 1.0000e-05\n",
            "Epoch 16/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0729 - recall: 0.5207 - precision: 0.7936 - val_loss: 0.0762 - val_recall: 0.5070 - val_precision: 0.7821 - lr: 1.0000e-05\n",
            "Epoch 17/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0721 - recall: 0.5267 - precision: 0.7946 - val_loss: 0.0758 - val_recall: 0.5156 - val_precision: 0.7808 - lr: 1.0000e-05\n",
            "Epoch 18/30\n",
            "117/117 [==============================] - 2s 19ms/step - loss: 0.0712 - recall: 0.5323 - precision: 0.7967 - val_loss: 0.0756 - val_recall: 0.5158 - val_precision: 0.7808 - lr: 1.0000e-05\n",
            "Epoch 19/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0703 - recall: 0.5382 - precision: 0.7983 - val_loss: 0.0752 - val_recall: 0.5218 - val_precision: 0.7781 - lr: 1.0000e-05\n",
            "Epoch 20/30\n",
            "117/117 [==============================] - 2s 21ms/step - loss: 0.0698 - recall: 0.5409 - precision: 0.8005 - val_loss: 0.0749 - val_recall: 0.5278 - val_precision: 0.7776 - lr: 1.0000e-05\n",
            "Epoch 21/30\n",
            "117/117 [==============================] - 3s 23ms/step - loss: 0.0691 - recall: 0.5471 - precision: 0.8006 - val_loss: 0.0746 - val_recall: 0.5293 - val_precision: 0.7771 - lr: 1.0000e-05\n",
            "Epoch 22/30\n",
            "117/117 [==============================] - 3s 22ms/step - loss: 0.0688 - recall: 0.5543 - precision: 0.7998 - val_loss: 0.0744 - val_recall: 0.5360 - val_precision: 0.7732 - lr: 1.0000e-05\n",
            "Epoch 23/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0680 - recall: 0.5565 - precision: 0.8039 - val_loss: 0.0741 - val_recall: 0.5366 - val_precision: 0.7769 - lr: 1.0000e-05\n",
            "Epoch 24/30\n",
            "117/117 [==============================] - 2s 13ms/step - loss: 0.0675 - recall: 0.5591 - precision: 0.8037 - val_loss: 0.0741 - val_recall: 0.5364 - val_precision: 0.7746 - lr: 1.0000e-05\n",
            "Epoch 25/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0667 - recall: 0.5633 - precision: 0.8099 - val_loss: 0.0736 - val_recall: 0.5389 - val_precision: 0.7784 - lr: 1.0000e-05\n",
            "Epoch 26/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0667 - recall: 0.5688 - precision: 0.8049 - val_loss: 0.0736 - val_recall: 0.5451 - val_precision: 0.7759 - lr: 1.0000e-05\n",
            "Epoch 27/30\n",
            "117/117 [==============================] - 2s 13ms/step - loss: 0.0658 - recall: 0.5730 - precision: 0.8082 - val_loss: 0.0736 - val_recall: 0.5415 - val_precision: 0.7745 - lr: 1.0000e-05\n",
            "Epoch 28/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0658 - recall: 0.5704 - precision: 0.8027 - val_loss: 0.0733 - val_recall: 0.5451 - val_precision: 0.7781 - lr: 1.0000e-05\n",
            "Epoch 29/30\n",
            "117/117 [==============================] - 2s 18ms/step - loss: 0.0651 - recall: 0.5776 - precision: 0.8067 - val_loss: 0.0733 - val_recall: 0.5497 - val_precision: 0.7706 - lr: 1.0000e-05\n",
            "Epoch 30/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0648 - recall: 0.5787 - precision: 0.8089 - val_loss: 0.0732 - val_recall: 0.5486 - val_precision: 0.7710 - lr: 1.0000e-05\n",
            "Model: \"model_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_18 (InputLayer)       [(None, 10, 128)]         0         \n",
            "                                                                 \n",
            " flatten_17 (Flatten)        (None, 1280)              0         \n",
            "                                                                 \n",
            " dense_51 (Dense)            (None, 4096)              5246976   \n",
            "                                                                 \n",
            " dropout_20 (Dropout)        (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_52 (Dense)            (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dense_53 (Dense)            (None, 20)                81940     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 22,110,228\n",
            "Trainable params: 22,110,228\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "117/117 [==============================] - 3s 21ms/step - loss: 0.2292 - recall: 0.0181 - precision: 0.0376 - val_loss: 0.1672 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-05\n",
            "Epoch 2/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.1568 - recall: 0.0040 - precision: 1.0000 - val_loss: 0.1392 - val_recall: 0.0201 - val_precision: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 3/30\n",
            "117/117 [==============================] - 3s 22ms/step - loss: 0.1294 - recall: 0.0573 - precision: 0.9470 - val_loss: 0.1133 - val_recall: 0.1209 - val_precision: 0.9349 - lr: 1.0000e-05\n",
            "Epoch 4/30\n",
            "117/117 [==============================] - 2s 21ms/step - loss: 0.1086 - recall: 0.1909 - precision: 0.8887 - val_loss: 0.0985 - val_recall: 0.2406 - val_precision: 0.8724 - lr: 1.0000e-05\n",
            "Epoch 5/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0971 - recall: 0.2933 - precision: 0.8341 - val_loss: 0.0914 - val_recall: 0.3288 - val_precision: 0.8343 - lr: 1.0000e-05\n",
            "Epoch 6/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0906 - recall: 0.3560 - precision: 0.8093 - val_loss: 0.0873 - val_recall: 0.3748 - val_precision: 0.8104 - lr: 1.0000e-05\n",
            "Epoch 7/30\n",
            "117/117 [==============================] - 2s 19ms/step - loss: 0.0867 - recall: 0.4013 - precision: 0.7962 - val_loss: 0.0846 - val_recall: 0.4031 - val_precision: 0.8054 - lr: 1.0000e-05\n",
            "Epoch 8/30\n",
            "117/117 [==============================] - 2s 21ms/step - loss: 0.0835 - recall: 0.4303 - precision: 0.7957 - val_loss: 0.0827 - val_recall: 0.4275 - val_precision: 0.7963 - lr: 1.0000e-05\n",
            "Epoch 9/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0815 - recall: 0.4477 - precision: 0.7876 - val_loss: 0.0812 - val_recall: 0.4468 - val_precision: 0.7914 - lr: 1.0000e-05\n",
            "Epoch 10/30\n",
            "117/117 [==============================] - 3s 25ms/step - loss: 0.0796 - recall: 0.4653 - precision: 0.7856 - val_loss: 0.0804 - val_recall: 0.4638 - val_precision: 0.7838 - lr: 1.0000e-05\n",
            "Epoch 11/30\n",
            "117/117 [==============================] - 3s 23ms/step - loss: 0.0780 - recall: 0.4790 - precision: 0.7903 - val_loss: 0.0794 - val_recall: 0.4742 - val_precision: 0.7829 - lr: 1.0000e-05\n",
            "Epoch 12/30\n",
            "117/117 [==============================] - 2s 21ms/step - loss: 0.0771 - recall: 0.4878 - precision: 0.7890 - val_loss: 0.0785 - val_recall: 0.4842 - val_precision: 0.7800 - lr: 1.0000e-05\n",
            "Epoch 13/30\n",
            "117/117 [==============================] - 2s 21ms/step - loss: 0.0756 - recall: 0.4990 - precision: 0.7909 - val_loss: 0.0777 - val_recall: 0.4893 - val_precision: 0.7779 - lr: 1.0000e-05\n",
            "Epoch 14/30\n",
            "117/117 [==============================] - 2s 21ms/step - loss: 0.0746 - recall: 0.5108 - precision: 0.7942 - val_loss: 0.0773 - val_recall: 0.4981 - val_precision: 0.7756 - lr: 1.0000e-05\n",
            "Epoch 15/30\n",
            "117/117 [==============================] - 2s 21ms/step - loss: 0.0736 - recall: 0.5162 - precision: 0.7942 - val_loss: 0.0771 - val_recall: 0.5032 - val_precision: 0.7776 - lr: 1.0000e-05\n",
            "Epoch 16/30\n",
            "117/117 [==============================] - 2s 21ms/step - loss: 0.0728 - recall: 0.5216 - precision: 0.7955 - val_loss: 0.0762 - val_recall: 0.5118 - val_precision: 0.7766 - lr: 1.0000e-05\n",
            "Epoch 17/30\n",
            "117/117 [==============================] - 2s 19ms/step - loss: 0.0719 - recall: 0.5261 - precision: 0.7982 - val_loss: 0.0758 - val_recall: 0.5141 - val_precision: 0.7808 - lr: 1.0000e-05\n",
            "Epoch 18/30\n",
            "117/117 [==============================] - 2s 21ms/step - loss: 0.0712 - recall: 0.5338 - precision: 0.7946 - val_loss: 0.0756 - val_recall: 0.5222 - val_precision: 0.7737 - lr: 1.0000e-05\n",
            "Epoch 19/30\n",
            "117/117 [==============================] - 2s 21ms/step - loss: 0.0707 - recall: 0.5345 - precision: 0.7957 - val_loss: 0.0754 - val_recall: 0.5200 - val_precision: 0.7781 - lr: 1.0000e-05\n",
            "Epoch 20/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0702 - recall: 0.5409 - precision: 0.7972 - val_loss: 0.0751 - val_recall: 0.5256 - val_precision: 0.7766 - lr: 1.0000e-05\n",
            "Epoch 21/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0693 - recall: 0.5475 - precision: 0.8019 - val_loss: 0.0748 - val_recall: 0.5265 - val_precision: 0.7779 - lr: 1.0000e-05\n",
            "Epoch 22/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0690 - recall: 0.5521 - precision: 0.8010 - val_loss: 0.0746 - val_recall: 0.5304 - val_precision: 0.7759 - lr: 1.0000e-05\n",
            "Epoch 23/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0683 - recall: 0.5539 - precision: 0.8032 - val_loss: 0.0744 - val_recall: 0.5333 - val_precision: 0.7758 - lr: 1.0000e-05\n",
            "Epoch 24/30\n",
            "117/117 [==============================] - 3s 21ms/step - loss: 0.0676 - recall: 0.5565 - precision: 0.8035 - val_loss: 0.0742 - val_recall: 0.5386 - val_precision: 0.7746 - lr: 1.0000e-05\n",
            "Epoch 25/30\n",
            "117/117 [==============================] - 3s 21ms/step - loss: 0.0670 - recall: 0.5605 - precision: 0.8036 - val_loss: 0.0739 - val_recall: 0.5437 - val_precision: 0.7789 - lr: 1.0000e-05\n",
            "Epoch 26/30\n",
            "117/117 [==============================] - 2s 21ms/step - loss: 0.0666 - recall: 0.5668 - precision: 0.8071 - val_loss: 0.0735 - val_recall: 0.5437 - val_precision: 0.7792 - lr: 1.0000e-05\n",
            "Epoch 27/30\n",
            "117/117 [==============================] - 2s 13ms/step - loss: 0.0665 - recall: 0.5720 - precision: 0.8041 - val_loss: 0.0736 - val_recall: 0.5506 - val_precision: 0.7760 - lr: 1.0000e-05\n",
            "Epoch 28/30\n",
            "117/117 [==============================] - 3s 25ms/step - loss: 0.0658 - recall: 0.5712 - precision: 0.8057 - val_loss: 0.0732 - val_recall: 0.5479 - val_precision: 0.7790 - lr: 1.0000e-05\n",
            "Epoch 29/30\n",
            "117/117 [==============================] - 2s 16ms/step - loss: 0.0653 - recall: 0.5772 - precision: 0.8090 - val_loss: 0.0733 - val_recall: 0.5544 - val_precision: 0.7712 - lr: 1.0000e-05\n",
            "Epoch 30/30\n",
            "117/117 [==============================] - 2s 19ms/step - loss: 0.0648 - recall: 0.5783 - precision: 0.8091 - val_loss: 0.0732 - val_recall: 0.5546 - val_precision: 0.7727 - lr: 1.0000e-05\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import necessary layers  \n",
        "from tensorflow.keras.layers import Input, Conv2D \n",
        "from tensorflow.keras.layers import MaxPool2D, Flatten, Dense, Dropout \n",
        "from tensorflow.keras import Model\n",
        "\n",
        "input = Input(shape =(10, 128))\n",
        "# Fully connected layer classifier\n",
        "x = Flatten()(input)\n",
        "x = Dense(units = 4096, activation ='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(units = 4096, activation ='relu')(x)\n",
        "# x = Dropout(0.5)(x)\n",
        "output = Dense(units = 20, activation ='sigmoid')(x)\n",
        "\n",
        "# creating the model\n",
        "model = Model (inputs=input, outputs =output)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAIG-i8CJbf_",
        "outputId": "ec83d775-2de2-433f-c38b-46f3a8cefa3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_8 (InputLayer)        [(None, 10, 128)]         0         \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 1280)              0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 4096)              5246976   \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 20)                81940     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 22,110,228\n",
            "Trainable params: 22,110,228\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LR = 1e-5 # Keep it small when transfer learning\n",
        "EPOCHS = 30\n",
        "loss_fn = tf.keras.losses.BinaryCrossentropy()"
      ],
      "metadata": {
        "id": "nAVOuQpZJTRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(learning_rate=LR),\n",
        "  loss=loss_fn, metrics = ['Recall', 'Precision'])"
      ],
      "metadata": {
        "id": "JEE3Q2x-cfCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
        "mcp_save = ModelCheckpoint('mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
        "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=7, verbose=1, epsilon=1e-4, mode='min')\n",
        "\n",
        "history = model.fit(x_train, epochs = EPOCHS, callbacks=[earlyStopping, mcp_save, reduce_lr_loss], validation_data = x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-FurJiIcgn5",
        "outputId": "1e88674b-99d5-47b5-ce53-ff823285a8f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "117/117 [==============================] - 3s 23ms/step - loss: 0.2215 - recall: 0.0137 - precision: 0.0456 - val_loss: 0.1663 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-05\n",
            "Epoch 2/30\n",
            "117/117 [==============================] - 2s 21ms/step - loss: 0.1559 - recall: 0.0048 - precision: 0.9844 - val_loss: 0.1382 - val_recall: 0.0268 - val_precision: 0.9918 - lr: 1.0000e-05\n",
            "Epoch 3/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.1287 - recall: 0.0641 - precision: 0.9491 - val_loss: 0.1118 - val_recall: 0.1304 - val_precision: 0.9394 - lr: 1.0000e-05\n",
            "Epoch 4/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.1075 - recall: 0.1962 - precision: 0.8780 - val_loss: 0.0973 - val_recall: 0.2590 - val_precision: 0.8616 - lr: 1.0000e-05\n",
            "Epoch 5/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0963 - recall: 0.3026 - precision: 0.8306 - val_loss: 0.0901 - val_recall: 0.3367 - val_precision: 0.8302 - lr: 1.0000e-05\n",
            "Epoch 6/30\n",
            "117/117 [==============================] - 3s 29ms/step - loss: 0.0898 - recall: 0.3618 - precision: 0.8069 - val_loss: 0.0861 - val_recall: 0.3845 - val_precision: 0.8075 - lr: 1.0000e-05\n",
            "Epoch 7/30\n",
            "117/117 [==============================] - 2s 21ms/step - loss: 0.0858 - recall: 0.4056 - precision: 0.7980 - val_loss: 0.0837 - val_recall: 0.4180 - val_precision: 0.7966 - lr: 1.0000e-05\n",
            "Epoch 8/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0832 - recall: 0.4335 - precision: 0.7947 - val_loss: 0.0821 - val_recall: 0.4428 - val_precision: 0.7865 - lr: 1.0000e-05\n",
            "Epoch 9/30\n",
            "117/117 [==============================] - 2s 19ms/step - loss: 0.0806 - recall: 0.4551 - precision: 0.7928 - val_loss: 0.0807 - val_recall: 0.4563 - val_precision: 0.7798 - lr: 1.0000e-05\n",
            "Epoch 10/30\n",
            "117/117 [==============================] - 3s 26ms/step - loss: 0.0791 - recall: 0.4706 - precision: 0.7895 - val_loss: 0.0795 - val_recall: 0.4720 - val_precision: 0.7767 - lr: 1.0000e-05\n",
            "Epoch 11/30\n",
            "117/117 [==============================] - 2s 21ms/step - loss: 0.0777 - recall: 0.4809 - precision: 0.7889 - val_loss: 0.0788 - val_recall: 0.4793 - val_precision: 0.7768 - lr: 1.0000e-05\n",
            "Epoch 12/30\n",
            "117/117 [==============================] - 2s 19ms/step - loss: 0.0764 - recall: 0.4894 - precision: 0.7865 - val_loss: 0.0780 - val_recall: 0.4855 - val_precision: 0.7760 - lr: 1.0000e-05\n",
            "Epoch 13/30\n",
            "117/117 [==============================] - 2s 21ms/step - loss: 0.0751 - recall: 0.4977 - precision: 0.7919 - val_loss: 0.0774 - val_recall: 0.4950 - val_precision: 0.7745 - lr: 1.0000e-05\n",
            "Epoch 14/30\n",
            "117/117 [==============================] - 2s 19ms/step - loss: 0.0743 - recall: 0.5116 - precision: 0.7925 - val_loss: 0.0768 - val_recall: 0.5037 - val_precision: 0.7749 - lr: 1.0000e-05\n",
            "Epoch 15/30\n",
            "117/117 [==============================] - 2s 21ms/step - loss: 0.0732 - recall: 0.5207 - precision: 0.7934 - val_loss: 0.0763 - val_recall: 0.5096 - val_precision: 0.7725 - lr: 1.0000e-05\n",
            "Epoch 16/30\n",
            "117/117 [==============================] - 2s 21ms/step - loss: 0.0722 - recall: 0.5266 - precision: 0.7954 - val_loss: 0.0759 - val_recall: 0.5101 - val_precision: 0.7779 - lr: 1.0000e-05\n",
            "Epoch 17/30\n",
            "117/117 [==============================] - 2s 21ms/step - loss: 0.0715 - recall: 0.5281 - precision: 0.7953 - val_loss: 0.0754 - val_recall: 0.5174 - val_precision: 0.7759 - lr: 1.0000e-05\n",
            "Epoch 18/30\n",
            "117/117 [==============================] - 2s 19ms/step - loss: 0.0709 - recall: 0.5366 - precision: 0.7951 - val_loss: 0.0753 - val_recall: 0.5209 - val_precision: 0.7702 - lr: 1.0000e-05\n",
            "Epoch 19/30\n",
            "117/117 [==============================] - 2s 19ms/step - loss: 0.0703 - recall: 0.5413 - precision: 0.8029 - val_loss: 0.0749 - val_recall: 0.5191 - val_precision: 0.7744 - lr: 1.0000e-05\n",
            "Epoch 20/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0697 - recall: 0.5455 - precision: 0.8002 - val_loss: 0.0746 - val_recall: 0.5335 - val_precision: 0.7702 - lr: 1.0000e-05\n",
            "Epoch 21/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0690 - recall: 0.5484 - precision: 0.8008 - val_loss: 0.0742 - val_recall: 0.5311 - val_precision: 0.7729 - lr: 1.0000e-05\n",
            "Epoch 22/30\n",
            "117/117 [==============================] - 2s 19ms/step - loss: 0.0684 - recall: 0.5523 - precision: 0.8027 - val_loss: 0.0740 - val_recall: 0.5393 - val_precision: 0.7685 - lr: 1.0000e-05\n",
            "Epoch 23/30\n",
            "117/117 [==============================] - 2s 13ms/step - loss: 0.0678 - recall: 0.5554 - precision: 0.8015 - val_loss: 0.0740 - val_recall: 0.5382 - val_precision: 0.7735 - lr: 1.0000e-05\n",
            "Epoch 24/30\n",
            "117/117 [==============================] - 2s 19ms/step - loss: 0.0673 - recall: 0.5628 - precision: 0.8055 - val_loss: 0.0736 - val_recall: 0.5433 - val_precision: 0.7688 - lr: 1.0000e-05\n",
            "Epoch 25/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0669 - recall: 0.5646 - precision: 0.8069 - val_loss: 0.0734 - val_recall: 0.5442 - val_precision: 0.7715 - lr: 1.0000e-05\n",
            "Epoch 26/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0665 - recall: 0.5655 - precision: 0.8042 - val_loss: 0.0733 - val_recall: 0.5428 - val_precision: 0.7720 - lr: 1.0000e-05\n",
            "Epoch 27/30\n",
            "117/117 [==============================] - 3s 23ms/step - loss: 0.0661 - recall: 0.5690 - precision: 0.8042 - val_loss: 0.0731 - val_recall: 0.5486 - val_precision: 0.7700 - lr: 1.0000e-05\n",
            "Epoch 28/30\n",
            "117/117 [==============================] - 3s 23ms/step - loss: 0.0651 - recall: 0.5751 - precision: 0.8113 - val_loss: 0.0731 - val_recall: 0.5517 - val_precision: 0.7677 - lr: 1.0000e-05\n",
            "Epoch 29/30\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0651 - recall: 0.5768 - precision: 0.8066 - val_loss: 0.0727 - val_recall: 0.5504 - val_precision: 0.7725 - lr: 1.0000e-05\n",
            "Epoch 30/30\n",
            "117/117 [==============================] - 1s 13ms/step - loss: 0.0646 - recall: 0.5783 - precision: 0.8085 - val_loss: 0.0728 - val_recall: 0.5504 - val_precision: 0.7718 - lr: 1.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list all data in history\n",
        "print(history.history.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViMCopeVcgh6",
        "outputId": "1d9e5360-ebfc-481d-de8e-01cd20666148"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'recall', 'precision', 'val_loss', 'val_recall', 'val_precision', 'lr'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for accuracy\n",
        "# plt.plot(history.history['recall'])\n",
        "# plt.plot(history.history['precision'])\n",
        "# plt.title('train precision-recall')\n",
        "# plt.ylabel('precision')\n",
        "# plt.xlabel('epoch')\n",
        "# plt.legend(['train', 'test'], loc='upper left')\n",
        "# plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "MbWhfv6-eYJm",
        "outputId": "a10ded66-3621-4199-e3d3-d9c89c1a5a62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "for seed in seeds:\n",
        "  model = load_model(f'mdl_wts_{seed}.hdf5')\n",
        "  y_pred = model.predict(x_test, batch_size = 1)\n",
        "  y_pred1 = np.where(y_pred >= 0.5, 1, 0)\n",
        "  print(classification_report(Y_test_labels, y_pred1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66iwhlyAyrjl",
        "outputId": "3d3c4004-2fe5-40d7-ada3-c0345a03f439"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40/40 [==============================] - 0s 6ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.03      0.02      0.02       115\n",
            "           1       0.01      0.01      0.01       140\n",
            "           2       0.00      0.00      0.00       134\n",
            "           3       0.09      0.04      0.06       226\n",
            "           4       0.00      0.00      0.00       137\n",
            "           5       0.06      0.05      0.06       297\n",
            "           6       0.05      0.04      0.04       278\n",
            "           7       0.02      0.01      0.01       175\n",
            "           8       0.09      0.08      0.08       286\n",
            "           9       0.02      0.01      0.01       211\n",
            "          10       0.06      0.05      0.05       193\n",
            "          11       0.10      0.03      0.05       121\n",
            "          12       0.07      0.07      0.07       285\n",
            "          13       0.05      0.05      0.05       305\n",
            "          14       0.06      0.06      0.06       268\n",
            "          15       0.03      0.02      0.02       228\n",
            "          16       0.04      0.03      0.03       318\n",
            "          17       0.02      0.02      0.02       182\n",
            "          18       0.10      0.07      0.09       394\n",
            "          19       0.08      0.06      0.07       224\n",
            "\n",
            "   micro avg       0.06      0.04      0.05      4517\n",
            "   macro avg       0.05      0.04      0.04      4517\n",
            "weighted avg       0.05      0.04      0.05      4517\n",
            " samples avg       0.03      0.03      0.03      4517\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40/40 [==============================] - 0s 6ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.02      0.01      0.01       115\n",
            "           1       0.02      0.01      0.02       140\n",
            "           2       0.02      0.01      0.01       134\n",
            "           3       0.09      0.05      0.06       226\n",
            "           4       0.03      0.01      0.01       137\n",
            "           5       0.07      0.05      0.06       297\n",
            "           6       0.04      0.03      0.04       278\n",
            "           7       0.05      0.03      0.04       175\n",
            "           8       0.06      0.06      0.06       286\n",
            "           9       0.06      0.03      0.04       211\n",
            "          10       0.04      0.04      0.04       193\n",
            "          11       0.02      0.01      0.01       121\n",
            "          12       0.08      0.07      0.07       285\n",
            "          13       0.04      0.04      0.04       305\n",
            "          14       0.06      0.06      0.06       268\n",
            "          15       0.04      0.02      0.03       228\n",
            "          16       0.05      0.03      0.04       318\n",
            "          17       0.04      0.04      0.04       182\n",
            "          18       0.11      0.08      0.09       394\n",
            "          19       0.05      0.04      0.04       224\n",
            "\n",
            "   micro avg       0.06      0.04      0.05      4517\n",
            "   macro avg       0.05      0.04      0.04      4517\n",
            "weighted avg       0.06      0.04      0.05      4517\n",
            " samples avg       0.03      0.03      0.03      4517\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40/40 [==============================] - 0s 6ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.05      0.03      0.04       115\n",
            "           1       0.04      0.03      0.03       140\n",
            "           2       0.04      0.01      0.02       134\n",
            "           3       0.01      0.00      0.01       226\n",
            "           4       0.02      0.01      0.01       137\n",
            "           5       0.07      0.05      0.06       297\n",
            "           6       0.08      0.05      0.06       278\n",
            "           7       0.02      0.01      0.01       175\n",
            "           8       0.06      0.06      0.06       286\n",
            "           9       0.04      0.03      0.03       211\n",
            "          10       0.06      0.05      0.05       193\n",
            "          11       0.03      0.01      0.01       121\n",
            "          12       0.07      0.06      0.07       285\n",
            "          13       0.08      0.07      0.07       305\n",
            "          14       0.06      0.06      0.06       268\n",
            "          15       0.06      0.04      0.04       228\n",
            "          16       0.06      0.04      0.05       318\n",
            "          17       0.03      0.03      0.03       182\n",
            "          18       0.12      0.08      0.10       394\n",
            "          19       0.05      0.04      0.05       224\n",
            "\n",
            "   micro avg       0.06      0.04      0.05      4517\n",
            "   macro avg       0.05      0.04      0.04      4517\n",
            "weighted avg       0.06      0.04      0.05      4517\n",
            " samples avg       0.03      0.03      0.03      4517\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40/40 [==============================] - 0s 5ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.02      0.01      0.01       115\n",
            "           1       0.01      0.01      0.01       140\n",
            "           2       0.08      0.04      0.05       134\n",
            "           3       0.03      0.01      0.02       226\n",
            "           4       0.03      0.01      0.01       137\n",
            "           5       0.06      0.05      0.06       297\n",
            "           6       0.06      0.04      0.05       278\n",
            "           7       0.05      0.03      0.03       175\n",
            "           8       0.05      0.05      0.05       286\n",
            "           9       0.05      0.03      0.04       211\n",
            "          10       0.03      0.02      0.02       193\n",
            "          11       0.10      0.03      0.05       121\n",
            "          12       0.06      0.06      0.06       285\n",
            "          13       0.06      0.05      0.05       305\n",
            "          14       0.07      0.06      0.06       268\n",
            "          15       0.05      0.03      0.04       228\n",
            "          16       0.05      0.03      0.04       318\n",
            "          17       0.03      0.02      0.02       182\n",
            "          18       0.12      0.08      0.10       394\n",
            "          19       0.04      0.03      0.04       224\n",
            "\n",
            "   micro avg       0.06      0.04      0.05      4517\n",
            "   macro avg       0.05      0.03      0.04      4517\n",
            "weighted avg       0.06      0.04      0.05      4517\n",
            " samples avg       0.03      0.03      0.03      4517\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40/40 [==============================] - 0s 6ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.04      0.02      0.02       115\n",
            "           1       0.06      0.04      0.04       140\n",
            "           2       0.02      0.01      0.01       134\n",
            "           3       0.05      0.03      0.04       226\n",
            "           4       0.00      0.00      0.00       137\n",
            "           5       0.06      0.05      0.05       297\n",
            "           6       0.07      0.05      0.06       278\n",
            "           7       0.05      0.03      0.04       175\n",
            "           8       0.08      0.07      0.08       286\n",
            "           9       0.06      0.03      0.04       211\n",
            "          10       0.05      0.04      0.04       193\n",
            "          11       0.02      0.01      0.01       121\n",
            "          12       0.05      0.05      0.05       285\n",
            "          13       0.08      0.08      0.08       305\n",
            "          14       0.08      0.07      0.07       268\n",
            "          15       0.05      0.03      0.04       228\n",
            "          16       0.07      0.04      0.05       318\n",
            "          17       0.04      0.04      0.04       182\n",
            "          18       0.10      0.07      0.08       394\n",
            "          19       0.02      0.02      0.02       224\n",
            "\n",
            "   micro avg       0.06      0.04      0.05      4517\n",
            "   macro avg       0.05      0.04      0.04      4517\n",
            "weighted avg       0.06      0.04      0.05      4517\n",
            " samples avg       0.03      0.03      0.03      4517\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(x_test, batch_size = 1)\n",
        "print(y_pred[0])\n",
        "y_pred1 = np.where(y_pred >= 0.5, 1, 0)\n",
        "print(y_pred1[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MA-Sc8Ie-k5",
        "outputId": "da996e7f-77e0-4fb7-c30c-dff004737852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40/40 [==============================] - 0s 6ms/step\n",
            "[2.1384990e-01 1.1609243e-03 1.4079579e-04 1.9858375e-02 8.4768385e-03\n",
            " 1.1870984e-03 7.2388037e-04 3.7915925e-03 1.0523508e-02 9.1048109e-04\n",
            " 9.0123899e-04 1.2783759e-02 1.3230937e-03 2.6681878e-02 9.0120435e-03\n",
            " 3.5972991e-03 5.7203528e-03 2.4728877e-03 2.4128115e-02 6.7566023e-03]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(multilabel_confusion_matrix(Y_test_labels, y_pred1))"
      ],
      "metadata": {
        "id": "eMLYlFu0fXRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(Y_test_labels, y_pred1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECUMXfiefW7k",
        "outputId": "108177ef-e8ea-4945-b671-f3e31d8972e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.02      0.01      0.01       115\n",
            "           1       0.06      0.04      0.05       140\n",
            "           2       0.04      0.01      0.02       134\n",
            "           3       0.05      0.03      0.03       226\n",
            "           4       0.00      0.00      0.00       137\n",
            "           5       0.07      0.06      0.06       297\n",
            "           6       0.06      0.04      0.05       278\n",
            "           7       0.01      0.01      0.01       175\n",
            "           8       0.06      0.05      0.06       286\n",
            "           9       0.04      0.02      0.03       211\n",
            "          10       0.04      0.04      0.04       193\n",
            "          11       0.02      0.01      0.01       121\n",
            "          12       0.07      0.06      0.06       285\n",
            "          13       0.07      0.07      0.07       305\n",
            "          14       0.10      0.09      0.09       268\n",
            "          15       0.03      0.02      0.02       228\n",
            "          16       0.08      0.05      0.06       318\n",
            "          17       0.04      0.04      0.04       182\n",
            "          18       0.09      0.07      0.08       394\n",
            "          19       0.05      0.04      0.04       224\n",
            "\n",
            "   micro avg       0.06      0.04      0.05      4517\n",
            "   macro avg       0.05      0.04      0.04      4517\n",
            "weighted avg       0.06      0.04      0.05      4517\n",
            " samples avg       0.03      0.03      0.03      4517\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zobl5Rs0gL56"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}