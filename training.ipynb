{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb851847-3977-4565-af1e-4569015dc0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/sagemaker-studiolab-notebooks\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "467088a4-97dc-46fc-96e7-606be2b5c298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/openmic-2018\n"
     ]
    }
   ],
   "source": [
    "cd openmic-2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45c529ed-d1e0-4131-820b-451356b82110",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "102af952-82e4-46ae-b2d6-ee33165a43a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-31 15:31:31.975532: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-31 15:31:33.086628: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-10-31 15:31:33.086699: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-10-31 15:31:33.086707: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "#!pip install pandas\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "#import wandb\n",
    "#from wandb.keras import WandbCallback\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b73f1e6-89d8-4a7f-a9a6-876fe7b93af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 10, 128) (20000, 20) (20000, 20) (20000,)\n"
     ]
    }
   ],
   "source": [
    "data = np.load(\"openmic-2018.npz\", allow_pickle = True)\n",
    "X, Y_true, Y_mask, sample_key = data['X'], data['Y_true'], data['Y_mask'], data['sample_key']\n",
    "print(X.shape, Y_true.shape, Y_mask.shape, sample_key.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a8dc369-f403-4459-9030-68a93866ea87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5     0.5     0.5     0.5     0.17105 0.5     0.5     0.      0.5\n",
      " 0.5     0.5     0.5     0.5     0.5     0.5     0.5     0.      0.5\n",
      " 0.5     0.5    ]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(Y_true[0])\n",
    "Y_true1 = np.where(Y_true > 0.5, 1, 0)\n",
    "print(Y_true1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09e93b5a-78b1-45de-96fb-72d24143fbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224 # Specify height and width of image to match the input format of the model\n",
    "CHANNELS = 3 # Keep RGB color channels to match the input format of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb97fcf8-e8cd-45ff-b9bf-3dcbff2f74ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_function(filename, label):\n",
    "    \"\"\"Function that returns a tuple of normalized image array and labels array.\n",
    "    Args:\n",
    "        filename: string representing path to image\n",
    "        label: 0/1 one-dimensional array of size N_LABELS\n",
    "    \"\"\"\n",
    "    # Read an image from a file\n",
    "    image_string = tf.io.read_file(filename)\n",
    "    # Decode it into a dense vector\n",
    "    image_decoded = tf.image.decode_jpeg(image_string, channels=CHANNELS)\n",
    "    # Resize it to fixed shape\n",
    "    image_resized = tf.image.resize(image_decoded, [IMG_SIZE, IMG_SIZE])\n",
    "    # Normalize it from [0, 255] to [0.0, 1.0]\n",
    "    image_normalized = image_resized / 255.0\n",
    "    return image_normalized, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f81cb30c-666b-4b18-b36b-aa973876fa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32 # Big enough to measure an F1-score\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE # Adapt preprocessing and prefetching dynamically to reduce GPU and CPU idle time\n",
    "SHUFFLE_BUFFER_SIZE = 128 # Shuffle the training data by a chunck of 128 observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fcf393c-9e27-43e4-ae49-1a0b9a3299f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(filenames, labels, is_training=True):\n",
    "    \"\"\"Load and parse dataset.\n",
    "    Args:\n",
    "        filenames: list of image paths\n",
    "        labels: numpy array of shape (BATCH_SIZE, N_LABELS)\n",
    "        is_training: boolean to indicate training mode\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a first dataset of file paths and labels\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "    # Parse and preprocess observations in parallel\n",
    "    dataset = dataset.map(parse_function, num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    # if is_training == True:\n",
    "    #     # This is a small dataset, only load it once, and keep it in memory.\n",
    "    #     dataset = dataset.cache()\n",
    "    # Shuffle the data each buffer size\n",
    "    # dataset = dataset.shuffle(buffer_size=SHUFFLE_BUFFER_SIZE)\n",
    "        \n",
    "    # Batch the data for multiple steps\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    # Fetch batches in the background while the model is training.\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3696c451-8abd-4ff9-889d-7e11daa278c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14915,)\n",
      "(5085,)\n",
      "(14915,)\n",
      "[29 30 31 32 33 34 35 36 37]\n"
     ]
    }
   ],
   "source": [
    "# PROLLY DONT NEED THIS\n",
    "# Load training split csv file\n",
    "with open(\"partitions/split01_train.csv\") as f:\n",
    "    train_IDs = f.readlines()\n",
    "    train_IDs = np.array([ID.strip() for ID in train_IDs])\n",
    "print(train_IDs.shape)\n",
    "\n",
    "# Load test split csv file\n",
    "with open(\"partitions/split01_test.csv\") as f:\n",
    "    test_IDs = f.readlines()\n",
    "    test_IDs = np.array([ID.strip() for ID in test_IDs])\n",
    "print(test_IDs.shape)\n",
    "\n",
    "# Get the training and testing split data into np arrays\n",
    "# Creates an array, which contains the index of the sample in data.  \n",
    "train_index = np.array([i for i in range(20000) if sample_key[i] in train_IDs])\n",
    "test_index = np.array([i for i in range(20000) if sample_key[i] in test_IDs])\n",
    "\n",
    "print(train_index.shape)\n",
    "print(test_index[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03a811fc-d8e4-49ab-b502-ee2a37b8d5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/openmic-2018/audio-logmel/000/000135_483840.png\n",
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/openmic-2018/audio-logmel/000/000308_61440.png\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "train_paths = [f\"/home/studio-lab-user/sagemaker-studiolab-notebooks/openmic-2018/audio-logmel/{i[:3]}/{i}.png\" for i in train_IDs]\n",
    "print(train_paths[1])\n",
    "\n",
    "test_paths = [f\"/home/studio-lab-user/sagemaker-studiolab-notebooks/openmic-2018/audio-logmel/{i[:3]}/{i}.png\" for i in test_IDs]\n",
    "print(test_paths[1])\n",
    "\n",
    "train_labels = [Y_true1[i] for i in train_index]\n",
    "print(train_labels[1])\n",
    "\n",
    "test_labels = [Y_true1[i] for i in test_index]\n",
    "print(test_labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70bf00fd-00d5-46bb-9c94-c405c965dc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 20), dtype=tf.int64, name=None))>\n",
      "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 20), dtype=tf.int64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "x_train = create_dataset(train_paths, train_labels)\n",
    "print(x_train)\n",
    "\n",
    "x_test = create_dataset(test_paths, test_labels)\n",
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8a49fb5-3cbb-4341-94b8-63d770bac94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 20)\n"
     ]
    }
   ],
   "source": [
    "for element in x_train.as_numpy_iterator():\n",
    "    print(element[1].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a7030e9-ff37-426a-b76c-9003487bc746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 112, 112, 64)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 56, 56, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 28, 28, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 14, 14, 512)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 100352)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              411045888 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 20)                81940     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 432,410,004\n",
      "Trainable params: 432,410,004\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# import necessary layers  \n",
    "from tensorflow.keras.layers import Input, Conv2D \n",
    "from tensorflow.keras.layers import MaxPool2D, Flatten, Dense \n",
    "from tensorflow.keras import Model\n",
    "# input\n",
    "\n",
    "input = Input(shape =(224,224,3))\n",
    "# 1st Conv Block\n",
    "x = Conv2D (filters =64, kernel_size =3, padding ='same', activation='relu')(input)\n",
    "x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
    "\n",
    "# 2nd Conv Block\n",
    "x = Conv2D (filters =128, kernel_size =3, padding ='same', activation='relu')(x)\n",
    "x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
    "\n",
    "# 3rd Conv block\n",
    "x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x)\n",
    "x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x)\n",
    "x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
    "\n",
    "# 4th Conv block\n",
    "x = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)\n",
    "x = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)\n",
    "x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
    "\n",
    "# Fully connected layers\n",
    "x = Flatten()(x)\n",
    "x = Dense(units = 4096, activation ='relu')(x)\n",
    "x = Dense(units = 4096, activation ='relu')(x)\n",
    "output = Dense(units = 20, activation ='sigmoid')(x)\n",
    "\n",
    "# creating the model\n",
    "\n",
    "model = Model (inputs=input, outputs =output)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f87a4089-e216-4ea1-886e-5957fdbcf1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-5 # Keep it small when transfer learning\n",
    "EPOCHS = 50\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0af41721-54f0-4c11-8a21-e2bd98bc5123",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=LR),\n",
    "  loss=loss_fn, metrics = ['Recall', 'Precision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca74e63b-ca43-44d9-b92a-8494c0eb1e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "mcp_save = ModelCheckpoint('mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, epsilon=1e-4, mode='min')\n",
    "\n",
    "history = model.fit(x_train, epochs = EPOCHS, callbacks=[earlyStopping, mcp_save, reduce_lr_loss], validation_data = x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a895857d-7f66-49b0-a4fd-e0cc3785c22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856cc8db-327f-4197-8a5d-654a8f2dc0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# summarize history for accuracy\n",
    "# plt.plot(history.history['recall'])\n",
    "# plt.plot(history.history['precision'])\n",
    "# plt.title('train precision-recall')\n",
    "# plt.ylabel('precision')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650b93e3-9afd-4b50-abf1-a9c8fe8c0a7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test, batch_size = 1)\n",
    "print(y_pred[0])\n",
    "y_pred1 = np.where(y_pred > 0.5, 1, 0)\n",
    "print(y_pred1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb5b6a7-7996-4eed-8222-68f292c770dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(multilabel_confusion_matrix(test_labels, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44372bd5-7ed4-49ec-be32-4d7a95d37e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_labels, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab27990-2619-4f30-be59-09bbe43922b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
